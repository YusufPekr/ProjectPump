{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from scipy.stats import boxcox\n",
    "from statsmodels.tsa.statespace.tools import diff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is a demo of how it could look in a real situation with forecast weather data (may require adjustments!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the reading of the data depends on on how it is retrieved\n",
    "# it is either all in one csv file or you have 2 files,\n",
    "# one for the historic data that is used for the training\n",
    "# and one for the forecast weather data that is used for forecasting energy\n",
    "# the data should be cleaned first\n",
    "\n",
    "# provide proper csv file names\n",
    "df_historic = pd.read_csv('(...).csv')\n",
    "df_historic['date'] = pd.to_datetime(df_historic['(name of date column)'])\n",
    "forecast_weather = pd.read_csv('(...).csv')\n",
    "forecast_weather = pd.to_datetime(forecast_weather['(name of date column)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACF and PACF plots used to determine p, q values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to look for orders of sarimax:\n",
    "# look at lower order lags < 4 for p and q values\n",
    "# p value is significant lag in lower order of PACF plot, q value is significant lag in lower order ACF plot\n",
    "# seasonal P value is significant lag of seasonal lags (multiples of 4) in PACF plot, seasonal Q value is significant lag of seasonal lags in ACF plot\n",
    "def plot_acf_pacf(df: pd.DataFrame) -> None:\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12), facecolor='w')\n",
    "    \n",
    "    # Plot ACF\n",
    "    plot_acf(df, ax=ax1, zero=False)\n",
    "    ax1.set_title(\"ACF plot for Seasonal Differenced Series Energy Consumption\", fontsize=20)\n",
    "    ax1.set_ylabel(\"ACF\", fontsize=18)\n",
    "    ax1.set_xlabel(\"Lag\", fontsize=18)\n",
    "    ax1.tick_params(axis='both', labelsize=14)\n",
    "    ax1.grid(alpha=1)\n",
    "\n",
    "    # Plot PACF\n",
    "    plot_pacf(df, ax=ax2, zero=False)\n",
    "    ax2.set_title(\"PACF plot for Seasonal Differenced Energy Consumption\", fontsize=20) \n",
    "    ax2.set_ylabel(\"PACF\", fontsize=18)\n",
    "    ax2.set_xlabel(\"Lag\", fontsize=18)\n",
    "    ax2.tick_params(axis='both', labelsize=14)\n",
    "    ax2.grid(alpha=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "seasonal_diff = diff(df_historic['(energy consumption column name)'], k_diff=0, k_seasonal_diff=1, seasonal_periods=4)\n",
    "plot_acf_pacf(seasonal_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_date_start = '2023-05-13'\n",
    "missing_date_end = '2023-10-15 06:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this data contains a missing section between dates '2023-05-14' and '2023-10-15 06:00'\n",
    "# you might need to change this and/or add other missing parts\n",
    "_ , lambda_value = boxcox(df_historic.loc[(df_historic['date'] <= missing_date_start) | (df_historic['date'] >= missing_date_end), 'energy_consumption'] + 0.001)\n",
    "print(lambda_value)\n",
    "\n",
    "# -1. is a reciprocal\n",
    "# -.5 is a recriprocal square root\n",
    "# 0.0 is a log transformation\n",
    "# .5 is a square toot transform and\n",
    "# 1.0 is no transform.\n",
    "\n",
    "# custom root function lambda value\n",
    "_BASE_ = 1.05\n",
    "def custom_root(x, base):\n",
    "    return x ** (1 / base)\n",
    "def reverse_custom_root(y, base):\n",
    "    return y ** base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_date_start = '2023-05-13'\n",
    "missing_date_end = '2023-10-15 06:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust data\n",
    "# this data contains a missing section between dates '2023-05-14' and '2023-10-15 06:00'\n",
    "# you might need to change this and/or add other missing parts\n",
    "df_historic.loc[(df_historic['date'] > missing_date_start) & (df_historic['date'] < missing_date_end), '(energy consumption column name)'] = np.nan\n",
    "df_historic['(energy consumption column name)'] = df_historic['(energy consumption column name)'].apply(lambda x: x - 3 if x > 12 else x)\n",
    "df_historic['(energy consumption column name)'] = custom_root(df_historic['(energy consumption column name)'], _BASE_)\n",
    "\n",
    "# add holiday and workday effects\n",
    "holiday_start = \"2023-12-22\"\n",
    "holiday_end = \"2023-12-29\"\n",
    "df_historic['effects'] = np.where((df_historic['date'].dt.weekday < 5) & ~((df_historic['date'] >= holiday_start) & (df_historic['date'] <= holiday_end)),1,0)\n",
    "\n",
    "df_historic.set_index('date', inplace=True)\n",
    "forecast_weather.set_index('date', inplace=True)\n",
    "# instead of creating a train test split, now the historic data will be used to train the model\n",
    "# and the weather forecast will be used to make energy forecasts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanatory variables, depends on the column names and used variables\n",
    "# make sure the column of the historic weather are the same as the forecast weather data\n",
    "exogs = ['temperature','humidity','evaporation','wind_speed','effects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caution, running the gridsearch may take a while, recommend running this only once for search and then commening out\n",
    "\n",
    "orders = [(p, 0, q) for p in range(0, 3) for q in range(0, 3)]\n",
    "seasonals = [(P, 1, Q, 4) for P in range(1, 3) for Q in range(2, 3)]\n",
    "result_GS2 = []\n",
    "for order in orders:\n",
    "    for seasonal in seasonals:\n",
    "\n",
    "        model = SARIMAX(df_historic['(energy consumption column name)'], exog=df_historic[exogs], order=order, seasonal_order=seasonal)\n",
    "        results = model.fit(disp=False, method='powell')\n",
    "        \n",
    "        result_GS2.append({\n",
    "            'order': order,\n",
    "            'seasonal_order': seasonal,\n",
    "            'AIC': results.aic,\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(result_GS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df.sort_values(by='AIC', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best orders from grid search with lowest AIC: \n",
    "# train model\n",
    "model = SARIMAX(df_historic['(energy consumption column name)'], order=(2,0,0), seasonal_order=(2,1,2,4), exog=df_historic[exogs])\n",
    "model_fit = model.fit(disp=False, method='powell')\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get forecast and values\n",
    "forecast = model_fit.get_forecast(steps=len(forecast_weather), exog=forecast_weather[exogs])\n",
    "forecast_values = reverse_custom_root(forecast.predicted_mean.clip(lower=0),_BASE_)\n",
    "forecast_ci = reverse_custom_root(forecast.conf_int().clip(lower=0),_BASE_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with previous data could look something like this\n",
    "\n",
    "train_subset = df_historic[-int(len(df_historic) * 0.2):]\n",
    "\n",
    "plt.figure(figsize=(10, 2.5))\n",
    "plt.plot(train_subset.index, reverse_custom_root(train_subset['(energy consumption column name)'], _BASE_), label='Training', color='black')\n",
    "plt.plot(forecast_weather.index, forecast_values, label='Forecast', color='red')\n",
    "plt.fill_between(forecast_weather.index, forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1], color='pink', alpha=0.4)\n",
    "plt.legend()\n",
    "plt.title(\"Forecasted Heat Pump Energy Consumption (with Training Data)\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=14) \n",
    "plt.ylabel(\"kWh\", fontsize=14)  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics cant be performed without test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
